# **LYSO能谱增强模型 - 技术操作手册**

## 1. 引言

本手册是为希望使用、修改或扩展此项目的开发者和研究人员提供的详细技术指南。它将深入讲解项目的配置系统、标准工作流程和参数设置方法。

在开始之前，请确保您已经阅读了项目根目录下的 `README.md` 文件，以了解项目的总体目标和核心特性。

## 2. 核心理念：配置驱动的工作流

本项目的一切核心操作（训练、推理、数据处理）都由**配置文件**驱动。您几乎不需要修改任何Python代码即可运行完整的实验流程。这种设计的目的是为了保证实验的**可复现性**和**易管理性**。

我们采用了一个**两级配置系统**：

1.  **任务流配置 (`project_config.yaml`)**: 位于项目根目录，负责控制**做什么**（例如，是准备数据还是进行训练）。
2.  **实验参数配置 (`configs/*.yaml`)**: 位于 `configs/` 目录，负责定义**怎么做**（例如，用什么模型、什么学习率来训练）。

## 3. 参数设置详解

### 3.1 第一级：任务流配置 (`project_config.yaml`)

这个文件是您与项目交互的主要入口，特别是当您使用 `run_task.py` 脚本时。

| 段落 | 参数 | 类型 | 描述 | 示例 |
| :--- | :--- | :--- | :--- | :--- |
| `data_config` | `source_dir` | string | 存放原始 `.h5` 或 `.npy` 数据文件的目录。 | `data` |
| | `output_dir` | string | `prepare_data.py` 将自动分割的数据集存放于此。 | `dataset_split` |
| | `train_ratio` | float | 训练集比例。 | `0.7` |
| | `val_ratio` | float | 验证集比例。 | `0.15` |
| | `test_ratio` | float | 测试集比例。 | `0.15` |
| `training` | `config_file` | string | **[关键]** 指定进行训练时，使用 `configs/` 目录下的哪个实验参数配置文件。 | `configs/rtx4060_config.yaml` |
| | `quick_test.enabled` | boolean | 是否启用快速测试模式。 | `true` |
| | `quick_test.num_epochs` | integer | 快速测试时覆盖的训练轮数。 | `10` |
| | `resume.enabled` | boolean | 是否从检查点恢复训练。 | `false` |
| | `resume.checkpoint_path` | string | 要恢复的检查点文件路径。 | `checkpoints/checkpoint_epoch_50.pth` |
| `inference` | `checkpoint_dir` | string | 存放模型检查点的目录。 | `checkpoints` |
| | `checkpoint_name` | string | 用于推理的模型文件名。通常是 `best_model.pth`。 | `best_model.pth` |
| | `test_input` | string | 用于推理的单个样本文件路径。 | `dataset_split/test/sample_0000.h5` |
| | `output_dir` | string | 存放推理结果的目录。 | `results` |
| | `visualize` | boolean | 推理后是否生成可视化图像。 | `true` |
| `preprocessing` | `source_dir` | string | （用于大规模数据）要转换为LMDB的源数据目录。 | `dataset/train` |
| | `output_dir` | string | （用于大规模数据）LMDB文件的输出目录。 | `dataset/lmdb` |
| | `num_workers` | integer | 数据预处理时使用的CPU核心数。 | `8` |
| `monitoring` | `tensorboard_port` | integer | TensorBoard服务的端口号。 | `6006` |

### 3.2 第二级：实验参数配置 (`configs/*.yaml`)

这些文件是科学实验的核心，定义了复现一个结果所需的所有超参数。以 `configs/rtx4060_config.yaml` 为例：

| 段落 | 参数 | 类型 | 描述与设置建议 |
| :--- | :--- | :--- | :--- |
| `model` | `name` | string | 模型名称。`ImprovedSpectralResNet1D` 是带有SE注意力的最新版本。 |
| | `num_blocks` | integer | 残差块的数量。**必须是3的倍数**。增加会提升模型容量但消耗更多显存。 |
| | `channels` | integer | 基础通道数。模型的“宽度”，同样影响容量和显存。 |
| `training` | `num_epochs` | integer | 总训练轮数。 |
| | `batch_size` | integer | **物理批次大小**。指一次性送入GPU的样本数。 |
| | `learning_rate` | float | 学习率。 |
| | `gradient_accumulation_steps` | integer | **[性能关键]** 梯度累积步数。**有效批次大小 = `batch_size` * `gradient_accumulation_steps`**。这是在不增加显存的情况下模拟大批次训练的首选方法。 |
| | `mixed_precision` | boolean | **[性能关键]** 是否启用FP16混合精度训练。在现代GPU上**强烈建议开启 (`true`)**。 |
| | `gradient_clip` | float | 梯度裁剪阈值，有助于防止训练初期的梯度爆炸。设为`1.0`通常是安全的。 |
| `loss` | `type` | string | 损失函数类型。`optimized` 是在GPU上高效运行的版本。 |
| | `peak_weight` | float | 损失函数中，对能谱峰区域的加权倍数。值越高，模型越关注峰的重建。 |
| `data` | `format` | string | 数据格式。对于大数据集，推荐使用`lmdb`。 |
| | `train_path` | string | 训练数据路径。 |
| | `val_path` | string | 验证数据路径。 |
| | `num_workers` | integer | 数据加载时使用的工作进程数。在Linux上可设为`4`或`8`加速，在Windows上由于多进程限制，**必须设为`0`**。 |
| | `cache_size` | integer | `SpectralDataset` 使用的内存缓存大小（样本数）。 |

## 4. 标准工作流程 (Step-by-Step)

### 步骤一：准备数据

- **对于小/中型数据集**:
    1.  将您所有的原始数据文件（`.h5` 或 `.npy`）放入根目录下的 `data/` 文件夹。
    2.  运行 `prepare_data.py` 脚本，它会根据 `project_config.yaml` 中的比例自动将数据分割为训练、验证和测试集，并存放在 `dataset_split/` 目录。
        ```bash
        python prepare_data.py
        ```
- **对于大型数据集 (百万级以上)**:
    1.  为了极致的IO性能，建议先将数据转换为LMDB格式。
    2.  将原始数据按 `train` 和 `val` 分别放入不同目录（例如 `raw_data/train`, `raw_data/val`）。
    3.  运行 `data_preprocessor.py` 脚本：
        ```bash
        python utils/data_preprocessor.py --source_dir raw_data/train --output_dir dataset_lmdb/train --format lmdb
        python utils/data_preprocessor.py --source_dir raw_data/val --output_dir dataset_lmdb/val --format lmdb
        ```

### 步骤二：配置您的实验

1.  进入 `configs/` 目录，复制一份现有的配置文件，例如 `cp rtx4060_config.yaml my_experiment_config.yaml`。
2.  打开 `my_experiment_config.yaml`，根据您的需求修改参数（如`learning_rate`, `batch_size`等）。
3.  **(可选)** 如果您想使用 `run_task.py` 脚本，请打开 `project_config.yaml`，并将 `training.config_file` 指向您新建的配置文件：
    ```yaml
    training:
      config_file: "configs/my_experiment_config.yaml"
    ```

### 步骤三：开始训练

您有两种方式启动训练：

- **方式一 (推荐): 直接调用 `train_improved.py`**
    这种方式最灵活，允许命令行覆盖参数。
    ```bash
    # 使用您的新配置开始训练
    python train_improved.py --config configs/my_experiment_config.yaml

    # 在运行时覆盖批次大小和学习率
    python train_improved.py --config configs/my_experiment_config.yaml --batch_size 16 --learning_rate 0.0001
    ```

- **方式二: 使用任务调度器 `run_task.py`**
    这种方式更自动化，它会读取 `project_config.yaml` 来决定如何训练。
    ```bash
    # 确保 project_config.yaml 中的设置正确
    python run_task.py train-full
    ```

### 步骤四：监控与恢复

- **监控**: 在另一个终端中，启动TensorBoard来可视化损失、指标和学习率。
    ```bash
    tensorboard --logdir logs
    ```
- **恢复训练**: 如果训练意外中断，可以使用 `--resume` 参数从最后一个检查点无缝恢复。
    ```bash
    python train_improved.py --config <your_config.yaml> --resume checkpoints/checkpoint_epoch_XX.pth
    ```

### 步骤五：推理

训练完成后，最佳模型会以 `best_model.pth` 的名字保存在 `checkpoints/` 目录。

- **对单个文件推理**:
    ```bash
    python inference.py --checkpoint checkpoints/best_model.pth --input <path_to_your_test_file.h5> --visualize
    ```
- **对整个目录批量推理**:
    ```bash
    python inference.py --checkpoint checkpoints/best_model.pth --input dataset_split/test --output results --batch
    ```

---
**手册结束**